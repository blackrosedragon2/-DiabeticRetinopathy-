{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['install', 'aptos2019-blindness-detection', 'weights']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Flatten\n",
    "import keras\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "import os\n",
    "print(os.listdir('../input'))\n",
    "#install keras-efficientnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/install/efficientnet-0.0.3-py2.py3-none-any.whl\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-0.0.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U '../input/install/efficientnet-0.0.3-py2.py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        mask = gray_img>tol        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0):\n",
    "            return img\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "def circle_crop(img):   \n",
    "    #img = cv2.imread(img)\n",
    "    img = crop_image_from_gray(img)    \n",
    "    \n",
    "    height, width, depth = img.shape    \n",
    "    \n",
    "    x = int(width/2)\n",
    "    y = int(height/2)\n",
    "    r = np.amin((x,y))\n",
    "    \n",
    "    circle_img = np.zeros((height, width), np.uint8)\n",
    "    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n",
    "    img = cv2.bitwise_and(img, img, mask=circle_img)\n",
    "    img = crop_image_from_gray(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:336: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3662 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "l1=[s+'.png' for s in df['id_code']]\n",
    "df['id_code']=l1\n",
    "l2=[str(s) for s in df['diagnosis']]\n",
    "df['diagnosis']=l2\n",
    "#print(df)\n",
    "sigmaX=10\n",
    "IMG_SIZE=228\n",
    "def preprocess(img_name):\n",
    "    \n",
    "    image = cv2.imread(img_name)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = circle_crop(image)\n",
    "    image=cv2.addWeighted (image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    return(image)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_IMG_PATH='../input/aptos2019-blindness-detection/train_images'\n",
    "# Add Image augmentation to our generator\n",
    "train_datagen = ImageDataGenerator(rotation_range=15,horizontal_flip=True,zca_whitening=True)\n",
    "\n",
    "# Use the dataframe to define train and validation generators\n",
    "train_generator = train_datagen.flow_from_dataframe(df, \n",
    "                                                    x_col='id_code', \n",
    "                                                    y_col='diagnosis',\n",
    "                                                    directory = TRAIN_IMG_PATH,\n",
    "                                                    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode='sparse',\n",
    "                                                    preprocessing_function=preprocess, \n",
    "                                                    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Efficient Net\n",
    "from efficientnet import EfficientNetB5\n",
    "efficient_model=EfficientNetB5(weights=None,input_shape=(IMG_SIZE,IMG_SIZE,3),include_top=False)\n",
    "efficient_model.load_weights('../input/weights/efficientnet-b5_imagenet_1000_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Model)      (None, 8, 8, 2048)        28513520  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              268437504 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 296,961,269\n",
      "Trainable params: 268,447,749\n",
      "Non-trainable params: 28,513,520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(efficient_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2048))\n",
    "model.add(layers.LeakyReLU())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(5,activation='softmax'))\n",
    "\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\"\"\"\n",
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)\n",
    "\"\"\"\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 423s 4s/step - loss: 6.1669 - acc: 0.6105\n",
      "Epoch 2/20\n",
      "114/114 [==============================] - 407s 4s/step - loss: 5.5480 - acc: 0.6548\n",
      "Epoch 3/20\n",
      "114/114 [==============================] - 417s 4s/step - loss: 6.0294 - acc: 0.6248\n",
      "Epoch 4/20\n",
      "114/114 [==============================] - 420s 4s/step - loss: 6.8811 - acc: 0.5722\n",
      "Epoch 5/20\n",
      "114/114 [==============================] - 416s 4s/step - loss: 6.5435 - acc: 0.5937\n",
      "Epoch 6/20\n",
      "114/114 [==============================] - 406s 4s/step - loss: 7.7933 - acc: 0.5163\n",
      "Epoch 7/20\n",
      "114/114 [==============================] - 405s 4s/step - loss: 5.8498 - acc: 0.6369\n",
      "Epoch 8/20\n",
      "114/114 [==============================] - 404s 4s/step - loss: 5.9161 - acc: 0.6328\n",
      "Epoch 9/20\n",
      "114/114 [==============================] - 406s 4s/step - loss: 6.1188 - acc: 0.6202\n",
      "Epoch 10/20\n",
      "114/114 [==============================] - 403s 4s/step - loss: 5.6953 - acc: 0.6459\n",
      "Epoch 11/20\n",
      "114/114 [==============================] - 401s 4s/step - loss: 5.6216 - acc: 0.6510\n",
      "Epoch 12/20\n",
      "114/114 [==============================] - 403s 4s/step - loss: 5.9681 - acc: 0.6295\n",
      "Epoch 13/20\n",
      "114/114 [==============================] - 402s 4s/step - loss: 5.5849 - acc: 0.6532\n",
      "Epoch 14/20\n",
      "114/114 [==============================] - 403s 4s/step - loss: 5.6394 - acc: 0.6499\n",
      "Epoch 15/20\n",
      "114/114 [==============================] - 405s 4s/step - loss: 5.7253 - acc: 0.6448\n",
      "Epoch 16/20\n",
      "114/114 [==============================] - 402s 4s/step - loss: 6.0840 - acc: 0.6225\n",
      "Epoch 17/20\n",
      "114/114 [==============================] - 405s 4s/step - loss: 5.4331 - acc: 0.6627\n",
      "Epoch 18/20\n",
      "114/114 [==============================] - 404s 4s/step - loss: 5.5237 - acc: 0.6570\n",
      "Epoch 19/20\n",
      "114/114 [==============================] - 401s 4s/step - loss: 5.4214 - acc: 0.6636\n",
      "Epoch 20/20\n",
      "114/114 [==============================] - 404s 4s/step - loss: 5.6993 - acc: 0.6463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69f2d24d68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1928 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "#X_test = ImageDataset(csv_file = '../input/aptos2019-blindness-detection/test.csv', root_dir = '../input/aptos2019-blindness-detection/test_images/')\n",
    "df_test=pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n",
    "l1=[s+'.png' for s in df_test['id_code']]\n",
    "df_test['id_code']=l1\n",
    "#print(df_test)\n",
    "datagen=ImageDataGenerator()\n",
    "generator = datagen.flow_from_dataframe(df_test,x_col='id_code',\n",
    "                                        directory='../input/aptos2019-blindness-detection/test_images',\n",
    "                                        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode=None,\n",
    "                                        preprocessing_function=preprocess,\n",
    "                                        shuffle=False)  \n",
    "\n",
    "predictions = model.predict_generator(generator,1928)\n",
    "\"\"\"TEST_IMG_PATH='../input/aptos2019-blindness-detection/test_images'\n",
    "N = df_test.shape[0]\n",
    "x_test = np.empty((N, 224, 224, 3), dtype=np.float32)\n",
    "for i, image_id in enumerate(df_test['id_code']):\n",
    "    x_test[i, :, :, :] = preprocess(f'{TEST_IMG_PATH}/{image_id}')\"\"\"\n",
    "\n",
    "\n",
    "#print(np.argmax(predictions, axis=1))\n",
    "submission = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n",
    "submission['diagnosis'] = np.argmax(predictions,axis=1)    \n",
    "submission.to_csv('submission.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
